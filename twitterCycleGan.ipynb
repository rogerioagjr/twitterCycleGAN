{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "###################### USED IN DATA PREPARATION ######################\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import re\n",
    "######################################################################\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/joaogui1/twitterCycleGAN\" target=\"_blank\">https://app.wandb.ai/joaogui1/twitterCycleGAN</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/joaogui1/twitterCycleGAN/runs/7u2eqhnj\" target=\"_blank\">https://app.wandb.ai/joaogui1/twitterCycleGAN/runs/7u2eqhnj</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/joaogui1/twitterCycleGAN/runs/7u2eqhnj"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"twitterCycleGAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLR():\n",
    "    def __init__(self, n_epochs, decay_start_epoch):\n",
    "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = 0\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), \"Empty buffer or trying to create a black hole. Be careful.\"\n",
    "        self.max_size = max_size\n",
    "        self.data_src = []\n",
    "        self.data_lens = []\n",
    "\n",
    "    def push_and_pop(self, src, lens):\n",
    "        to_return_src = []\n",
    "        to_return_lens = []\n",
    "        src = src.transpose(0, 1)\n",
    "        for src_element, lens_element in zip(src, lens):\n",
    "            src_element = torch.unsqueeze(src_element, 0)\n",
    "            lens_element = torch.unsqueeze(lens_element, 0)\n",
    "            if len(self.data_src) < self.max_size:\n",
    "                self.data_src.append(src_element)\n",
    "                self.data_lens.append(lens_element)\n",
    "\n",
    "                to_return_src.append(src_element)\n",
    "                to_return_lens.append(lens_element)\n",
    "            else:\n",
    "                if random.uniform(0,1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size-1)\n",
    "                    to_return_src.append(self.data_src[i].clone())\n",
    "                    to_return_lens.append(self.data_lens[i].clone())\n",
    "\n",
    "                    self.data_src[i] = src_element\n",
    "                    self.data_lens[i] = lens_element\n",
    "                else:\n",
    "                    to_return_src.append(src_element)\n",
    "                    to_return_lens.append(lens_element)\n",
    "        return Variable(torch.cat(to_return_src).transpose(0, 1)), Variable(torch.cat(to_return_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embedded_size, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        positional_encoder = torch.zeros(max_len, embedded_size)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        normalizer = torch.exp(torch.arange(0, embedded_size, 2).float() * (-math.log(10000.0) / embedded_size))\n",
    "\n",
    "        positional_encoder[:, 0::2] = torch.sin(position * normalizer)\n",
    "        positional_encoder[:, 1::2] = torch.cos(position * normalizer)\n",
    "\n",
    "        positional_encoder = positional_encoder.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('positional_encoder', positional_encoder)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_pos = x + self.positional_encoder[:x.size(0), :]\n",
    "        return self.dropout(x_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_vocab_size, output_vocab_size, embedded_size, n_heads, n_hidden, n_layers,\n",
    "                 src_encoder, dropout=0.5, device='cuda', max_len=50, pad=0, sos=1, eos=2):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.model_type = 'Transformer'\n",
    "        self.sos = sos\n",
    "        self.eos = eos\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.embedded_size = embedded_size\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.src_encoder = src_encoder.to(device)\n",
    "\n",
    "        self.positional_encoder = PositionalEncoding(embedded_size, dropout)\n",
    "\n",
    "        encoder_layers = nn.TransformerEncoderLayer(embedded_size, n_heads, n_hidden, dropout)\n",
    "\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, n_layers)\n",
    "\n",
    "        decoder_layers = nn.TransformerDecoderLayer(embedded_size, n_heads, n_hidden, dropout)\n",
    "\n",
    "        self.trg_encoder = nn.Embedding(output_vocab_size, embedded_size, padding_idx=pad)\n",
    "\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layers, n_layers)\n",
    "\n",
    "        self.trg_decoder = nn.Linear(embedded_size, output_vocab_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_range = 0.1\n",
    "        self.src_encoder.weight.data.uniform_(-init_range, init_range)\n",
    "        self.trg_encoder.weight.data.uniform_(-init_range, init_range)\n",
    "        self.trg_decoder.bias.data.zero_()\n",
    "        self.trg_decoder.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "\n",
    "    def _generate_padding_mask_(self, batch_size, max_len, lens):\n",
    "        mask = torch.ones(batch_size, max_len, dtype=torch.bool)\n",
    "        for idx, length in enumerate(lens):\n",
    "            mask[idx][:length] = False\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def forward_one_word(self, src, trg, src_lens, trg_lens):\n",
    "        src_embeddings = self.src_encoder(src) * math.sqrt(self.embedded_size)\n",
    "        src_positional_embeddings = self.positional_encoder(src_embeddings)\n",
    "\n",
    "        max_len, batch_size = list(src.size())\n",
    "        src_padding_mask = self._generate_padding_mask_(batch_size, max_len, src_lens).to(self.device)\n",
    "        memory = self.transformer_encoder(src_positional_embeddings, src_key_padding_mask=src_padding_mask)\n",
    "\n",
    "        trg_embeddings = self.trg_encoder(trg) * math.sqrt(self.embedded_size)\n",
    "        trg_positional_embeddings = self.positional_encoder(trg_embeddings)\n",
    "\n",
    "        trg_padding_mask = self._generate_padding_mask_(batch_size, max_len, trg_lens).to(self.device)\n",
    "\n",
    "        output_embeddings = self.transformer_decoder(trg_positional_embeddings, memory,\n",
    "                                                     memory_key_padding_mask=src_padding_mask,\n",
    "                                                     tgt_key_padding_mask=trg_padding_mask,)\n",
    "        output = self.trg_decoder(output_embeddings)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def forward(self, src, src_lens):\n",
    "        max_len, batch_size = list(src.size())\n",
    "\n",
    "        trg = torch.zeros(max_len, batch_size, dtype=torch.long).to(self.device)\n",
    "        trg[0,:] = self.sos\n",
    "\n",
    "        trg_lens = torch.ones(batch_size, dtype=torch.long).to(self.device)\n",
    "        is_finished = torch.zeros(batch_size, dtype=torch.bool).to(self.device)\n",
    "\n",
    "        for idx in range(1, max_len-1):\n",
    "            output = self.forward_one_word(src, trg, src_lens, trg_lens)\n",
    "            pred = output[idx, :, :].max(1).indices\n",
    "            finished_now = (pred == self.eos)\n",
    "            trg_lens[finished_now] = idx+1\n",
    "            is_finished = is_finished | finished_now\n",
    "            trg[idx][~is_finished] = pred[~is_finished]\n",
    "\n",
    "        trg[max_len-1][~is_finished] = self.eos\n",
    "        trg_lens[~is_finished] = max_len\n",
    "\n",
    "        return trg, trg_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedded_size=32, n_heads=1, n_hidden=64, n_layers=1,\n",
    "                 dropout=0.1, max_len=50, device=torch.device('cuda'), pad=0):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedded_size = embedded_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.src_encoder = nn.Embedding(vocab_size, embedded_size, padding_idx=pad)\n",
    "        self.positional_encoder = PositionalEncoding(embedded_size, dropout)\n",
    "\n",
    "        encoder_layers = nn.TransformerEncoderLayer(embedded_size, n_heads, n_hidden, dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, n_layers)\n",
    "\n",
    "        self.decoder = nn.Linear(embedded_size*max_len, 1)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_range = 0.1\n",
    "        self.src_encoder.weight.data.uniform_(-init_range, init_range)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def _generate_padding_mask_(self, batch_size, max_len, lens):\n",
    "        mask = torch.ones(batch_size, max_len, dtype=torch.bool)\n",
    "        for idx, length in enumerate(lens):\n",
    "            mask[idx][:length] = False\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, src_lens):\n",
    "        src_embeddings = self.src_encoder(src) * math.sqrt(self.embedded_size)\n",
    "        src_positional_embeddings = self.positional_encoder(src_embeddings)\n",
    "\n",
    "        max_len, batch_size = list(src.size())\n",
    "        src_padding_mask = self._generate_padding_mask_(batch_size, max_len, src_lens).to(self.device)\n",
    "        src_embedding = self.transformer_encoder(src_positional_embeddings,\n",
    "                                                 src_key_padding_mask=src_padding_mask\n",
    "                                                 ).transpose(0,1).reshape(batch_size, -1).contiguous()\n",
    "        outputs = self.decoder(src_embedding)\n",
    "        return torch.sigmoid(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_sentences(src, src_lens, vocab_itos):\n",
    "    sentences_tokens = src.transpose(0, 1).tolist()\n",
    "    sentences = []\n",
    "    for idx, sentence_tokens in enumerate(sentences_tokens):\n",
    "        sentence = list(map(lambda x: vocab_itos[x], sentence_tokens[:src_lens[idx]]))\n",
    "        sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, user_A, user_B, n_epochs, decay_epoch, device):\n",
    "\n",
    "    ################### prepare the data ###################\n",
    "\n",
    "    def prepare_data(user, batch_size, max_len, vocab_itos, vocab_stoi, device):\n",
    "        train_df = pd.read_csv('data/' + user + '/train.csv')\n",
    "        val_df = pd.read_csv('data/' + user + '/val.csv')\n",
    "        test_df = pd.read_csv('data/' + user + '/test.csv')\n",
    "\n",
    "        train_tokens = torch.zeros(len(train_df), max_len, dtype=torch.long)\n",
    "        val_tokens = torch.zeros(len(val_df), max_len, dtype=torch.long)\n",
    "        test_tokens = torch.zeros(len(test_df), max_len, dtype=torch.long)\n",
    "\n",
    "        train_lens = torch.zeros(len(train_df), dtype=torch.long)\n",
    "        val_lens = torch.zeros(len(val_df), dtype=torch.long)\n",
    "        test_lens = torch.zeros(len(test_df), dtype=torch.long)\n",
    "\n",
    "        for i, tweet in enumerate(train_df['text']):\n",
    "            words = tweet.split(' ')\n",
    "            if len(words) > max_len - 2:\n",
    "                words = words[:max_len - 2]\n",
    "            words = ['<sos>'] + words + ['<eos>']\n",
    "            train_lens[i] = len(words)\n",
    "            for j, word in enumerate(words):\n",
    "                if word not in vocab_stoi:\n",
    "                    token = len(vocab_stoi)\n",
    "                    vocab_stoi[word] = token\n",
    "                    vocab_itos[token] = word\n",
    "                else:\n",
    "                    token = vocab_stoi[word]\n",
    "                train_tokens[i][j] = token\n",
    "\n",
    "        for i, tweet in enumerate(val_df['text']):\n",
    "            words = tweet.split(' ')\n",
    "            if len(words) > max_len - 2:\n",
    "                words = words[:max_len - 2]\n",
    "            words = ['<sos>'] + words + ['<eos>']\n",
    "            val_lens[i] = len(words)\n",
    "            for j, word in enumerate(words):\n",
    "                if word not in vocab_stoi:\n",
    "                    token = vocab_stoi['<unk>']\n",
    "                else:\n",
    "                    token = vocab_stoi[word]\n",
    "                val_tokens[i][j] = token\n",
    "\n",
    "            for i, tweet in enumerate(test_df['text']):\n",
    "                words = tweet.split(' ')\n",
    "                if len(words) > max_len - 2:\n",
    "                    words = words[:max_len - 2]\n",
    "                words = ['<sos>'] + words + ['<eos>']\n",
    "                test_lens[i] = len(words)\n",
    "                for j, word in enumerate(words):\n",
    "                    if word not in vocab_stoi:\n",
    "                        token = vocab_stoi['<unk>']\n",
    "                    else:\n",
    "                        token = vocab_stoi[word]\n",
    "                    val_tokens[i][j] = token\n",
    "\n",
    "        def batchify(tokens, lens, batch_size):\n",
    "            n_batches = tokens.size(0) // batch_size\n",
    "            data = tokens.narrow(0, 0, n_batches * batch_size)\n",
    "            lens = lens.narrow(0, 0, n_batches*batch_size)\n",
    "            data = data.view(n_batches, batch_size, -1).transpose(1,2).contiguous()\n",
    "            lens = lens.view(n_batches, batch_size).contiguous()\n",
    "            return data.to(device), lens.to(device)\n",
    "\n",
    "        train_data, train_lens = batchify(train_tokens, train_lens, batch_size)\n",
    "        val_data, val_lens = batchify(val_tokens, val_lens, batch_size)\n",
    "        test_data, test_lens = batchify(test_tokens, test_lens, batch_size)\n",
    "\n",
    "        return train_data, val_data, test_data, train_lens, val_lens, test_lens\n",
    "    ################### training settings ###################\n",
    "\n",
    "    batch_size = 20\n",
    "    max_len = 50\n",
    "\n",
    "    vocab_itos = {0: '<pad>', 1: '<sos>', 2: '<eos>', 3: '<unk>'}\n",
    "    vocab_stoi = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n",
    "\n",
    "    (A_train_data, A_val_data, A_test_data,\n",
    "     A_train_lens, A_val_lens, A_test_lens) = prepare_data(user_A, batch_size=batch_size, max_len=max_len,\n",
    "                                                           vocab_itos=vocab_itos, vocab_stoi=vocab_stoi, device=device)\n",
    "\n",
    "    (B_train_data, B_val_data, B_test_data,\n",
    "     B_train_lens, B_val_lens, B_test_lens) = prepare_data(user_B, batch_size=batch_size, max_len=max_len,\n",
    "                                                           vocab_itos=vocab_itos, vocab_stoi=vocab_stoi, device=device)\n",
    "\n",
    "    A_train_data = A_train_data.to(device)\n",
    "    B_train_data = B_train_data.to(device)\n",
    "\n",
    "    n_batches = A_train_data.size(0)\n",
    "\n",
    "    vocab_size = len(vocab_itos)\n",
    "\n",
    "    print('vocab size:', vocab_size)\n",
    "\n",
    "    G_embedded_size = 256\n",
    "    G_n_heads = 8\n",
    "    G_n_hidden = 1024\n",
    "    G_n_layers = 6\n",
    "    G_dropout = 0.1\n",
    "\n",
    "    shared_encoder = nn.Embedding(vocab_size, G_embedded_size, padding_idx=0).to(device)\n",
    "\n",
    "    netG_A2B = Generator(input_vocab_size=vocab_size, output_vocab_size=vocab_size, embedded_size=G_embedded_size,\n",
    "                         n_heads=G_n_heads, n_hidden=G_n_hidden, n_layers=G_n_layers, dropout=G_dropout,\n",
    "                         src_encoder=shared_encoder, device=device).to(device)\n",
    "\n",
    "    netG_B2A = Generator(input_vocab_size=vocab_size, output_vocab_size=vocab_size, embedded_size=G_embedded_size,\n",
    "                         n_heads=G_n_heads, n_hidden=G_n_hidden, n_layers=G_n_layers, dropout=G_dropout,\n",
    "                         src_encoder=shared_encoder, device=device).to(device)\n",
    "\n",
    "    D_embedded_size = 32\n",
    "    D_n_heads = 1\n",
    "    D_n_hidden = 64\n",
    "    D_n_layers = 1\n",
    "    D_dropout = 0.1\n",
    "\n",
    "    netD_A = Discriminator(vocab_size=vocab_size, embedded_size=D_embedded_size, n_heads=D_n_heads,\n",
    "                                  n_hidden=D_n_hidden, n_layers=D_n_layers, dropout=D_dropout,\n",
    "                                  device=device).to(device)\n",
    "\n",
    "    netD_B = Discriminator(vocab_size=vocab_size, embedded_size=D_embedded_size, n_heads=D_n_heads,\n",
    "                           n_hidden=D_n_hidden, n_layers=D_n_layers, dropout=D_dropout,\n",
    "                           device=device).to(device)\n",
    "\n",
    "    ################# training loop #################\n",
    "\n",
    "    # losses\n",
    "\n",
    "    criterion_GAN = torch.nn.MSELoss()\n",
    "    criterion_cycle = torch.nn.L1Loss()\n",
    "    criterion_identity = torch.nn.L1Loss()\n",
    "\n",
    "    # Optimizers & LR schedulers\n",
    "\n",
    "    lr = 0.0002\n",
    "    betas = (0.5, 0.999)\n",
    "\n",
    "    optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr=lr, betas=betas)\n",
    "    optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=lr/10, betas=betas)\n",
    "    optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=lr/10, betas=betas)\n",
    "\n",
    "    lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)\n",
    "    lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)\n",
    "    lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs, decay_epoch).step)\n",
    "\n",
    "    # Inputs & targets memory allocation\n",
    "\n",
    "    LongTensor = torch.cuda.LongTensor if device == 'cuda' else torch.LongTensor\n",
    "    FloatTensor = torch.cuda.FloatTensor if device == 'cuda' else torch.FloatTensor\n",
    "    A_src = LongTensor(max_len, batch_size)\n",
    "    A_lens = LongTensor(batch_size)\n",
    "    B_src = LongTensor(max_len, batch_size)\n",
    "    B_lens = LongTensor(batch_size)\n",
    "    target_real = Variable(FloatTensor(batch_size).fill_(1.0), requires_grad=False)\n",
    "    target_fake = Variable(FloatTensor(batch_size).fill_(0.0), requires_grad=False)\n",
    "\n",
    "    fake_A_buffer = ReplayBuffer()\n",
    "    fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "    n_fixed = 5\n",
    "\n",
    "    fixed_A_src = A_train_data[0, :, :n_fixed]\n",
    "    fixed_A_lens = A_train_lens[0, :n_fixed]\n",
    "    A_tweets_list = []\n",
    "\n",
    "    fixed_B_src = B_train_data[0, :, :n_fixed]\n",
    "    fixed_B_lens = B_train_lens[0, :n_fixed]\n",
    "    B_tweets_list = []\n",
    "\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "\n",
    "    D_x_list = []\n",
    "    D_G_x_list = []\n",
    "\n",
    "    loss_identity_list = []\n",
    "    loss_GAN_list = []\n",
    "    loss_cycle_list = []\n",
    "\n",
    "    loss_D_real_list = []\n",
    "    loss_D_fake_list = []\n",
    "\n",
    "    # Training\n",
    "    print(\"Starting Training Loop...\")\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_idx in range(n_batches):\n",
    "            real_A_src = Variable(A_src.copy_(A_train_data[batch_idx]))\n",
    "            real_A_lens = Variable(A_lens.copy_(A_train_lens[batch_idx]))\n",
    "\n",
    "            real_B_src = Variable(B_src.copy_(B_train_data[batch_idx]))\n",
    "            real_B_lens = Variable(B_lens.copy_(B_train_lens[batch_idx]))\n",
    "\n",
    "            ##############################################################\n",
    "            #                     Update Generators                      #\n",
    "            ##############################################################\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Identity loss: G_A2B(B) = B and vice versa\n",
    "            same_B_src, same_B_lens = netG_A2B(real_B_src, real_B_lens)\n",
    "            embedded_same_B = shared_encoder(same_B_src)\n",
    "            embedded_real_B = shared_encoder(real_B_src)\n",
    "            loss_identity_B = criterion_identity(embedded_same_B, embedded_real_B) * 5.0\n",
    "            wandb.log({\"Identity loss B\": loss_identity_B})\n",
    "\n",
    "            same_A_src, same_A_lens = netG_B2A(real_A_src, real_A_lens)\n",
    "            embedded_same_A = shared_encoder(same_A_src)\n",
    "            embedded_real_A = shared_encoder(real_A_src)\n",
    "            loss_identity_A = criterion_identity(embedded_same_A, embedded_real_A) * 5.0\n",
    "            wandb.log({\"Identity loss A\": loss_identity_A})\n",
    "            \n",
    "            # GAN loss\n",
    "            fake_B_src, fake_B_lens = netG_A2B(real_A_src, real_A_lens)\n",
    "            pred_fake = netD_B(fake_B_src, fake_B_lens).view(-1)\n",
    "            loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "            wandb.log({\"GAN loss A\": loss_GAN_A2B})\n",
    "            \n",
    "            fake_A_src, fake_A_lens = netG_B2A(real_B_src, real_B_lens)\n",
    "            pred_fake = netD_A(fake_A_src, fake_A_lens).view(-1)\n",
    "            loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
    "            wandb.log({\"GAN loss B\": loss_GAN_B2A})\n",
    "            \n",
    "            # Cycle loss\n",
    "            recovered_A_scr, recovered_A_lens = netG_B2A(fake_B_src, fake_B_lens)\n",
    "            embedded_recovered_A = shared_encoder(recovered_A_scr)\n",
    "            loss_cycle_ABA = criterion_cycle(embedded_recovered_A, embedded_real_A) * 10.0\n",
    "            wandb.log({\"Cycle loss ABA\": loss_cycle_ABA})\n",
    "            \n",
    "            recovered_B_scr, recovered_B_lens = netG_A2B(fake_A_src, fake_A_lens)\n",
    "            embedded_recovered_B = shared_encoder(recovered_B_scr)\n",
    "            loss_cycle_BAB = criterion_cycle(embedded_recovered_B, embedded_real_B)*10.0\n",
    "            wandb.log({\"Cycle loss BAB\": loss_cycle_BAB})\n",
    "            \n",
    "            # Total loss\n",
    "            loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "            loss_G.backward()\n",
    "\n",
    "            optimizer_G.step()\n",
    "\n",
    "            loss_identity = loss_identity_A + loss_identity_B\n",
    "            loss_GAN = loss_GAN_A2B + loss_GAN_B2A\n",
    "            loss_cycle = loss_cycle_ABA + loss_cycle_BAB\n",
    "\n",
    "            ##############################################################\n",
    "            #                   Update Discriminator A                   #\n",
    "            ##############################################################\n",
    "\n",
    "            optimizer_D_A.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = netD_A(real_A_src, real_A_lens).view(-1)\n",
    "            D_A_x = pred_real.mean().item()\n",
    "\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_A_src, fake_A_lens = fake_A_buffer.push_and_pop(fake_A_src, fake_A_lens)\n",
    "            pred_fake = netD_A(fake_A_src.detach(), fake_A_lens.detach()).view(-1)\n",
    "            D_A_G_x = pred_fake.mean().item()\n",
    "\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_A = (loss_D_real + loss_D_fake) * 0.5\n",
    "            loss_D_A.backward()\n",
    "\n",
    "            optimizer_D_A.step()\n",
    "\n",
    "            loss_D_A_real = loss_D_real\n",
    "            loss_D_A_fake = loss_D_fake\n",
    "\n",
    "            ##############################################################\n",
    "            #                   Update Discriminator B                   #\n",
    "            ##############################################################\n",
    "\n",
    "            optimizer_D_B.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = netD_B(real_B_src, real_B_lens).view(-1)\n",
    "            D_B_x = pred_real.mean().item()\n",
    "\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_B_src, fake_B_lens = fake_B_buffer.push_and_pop(fake_B_src, fake_B_lens)\n",
    "            pred_fake = netD_B(fake_B_src.detach(), fake_B_lens.detach()).view(-1)\n",
    "            D_B_G_x = pred_fake.mean().item()\n",
    "\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_B = (loss_D_real + loss_D_fake) * 0.5\n",
    "            loss_D_B.backward()\n",
    "\n",
    "            optimizer_D_B.step()\n",
    "\n",
    "            loss_D_B_real = loss_D_real\n",
    "            loss_D_B_fake = loss_D_fake\n",
    "\n",
    "            loss_D_real = loss_D_A_real + loss_D_B_real\n",
    "            loss_D_fake = loss_D_A_fake + loss_D_B_fake\n",
    "\n",
    "            ##############################################################\n",
    "            #                   Output Training Stats                    #\n",
    "            ##############################################################\n",
    "\n",
    "            D_x = (D_A_x + D_B_x) / 2\n",
    "            D_G_x = (D_A_G_x + D_B_G_x) / 2\n",
    "\n",
    "            loss_D = loss_D_A + loss_D_B\n",
    "\n",
    "            if batch_idx % 20 == 0 or batch_idx == n_batches - 1:\n",
    "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): '\n",
    "                      '%.4f\\tD(G(x)): %.4f' % (epoch, n_epochs, batch_idx, n_batches, loss_D.item(),\n",
    "                                                      loss_G.item(), D_x, D_G_x))\n",
    "\n",
    "            D_losses.append(loss_D.item())\n",
    "            G_losses.append(loss_G.item())\n",
    "\n",
    "            D_x_list.append(D_x)\n",
    "            D_G_x_list.append(D_G_x)\n",
    "\n",
    "            loss_identity_list.append(loss_identity.item())\n",
    "            loss_GAN_list.append(loss_GAN.item())\n",
    "            loss_cycle_list.append(loss_cycle.item())\n",
    "\n",
    "            loss_D_real_list.append(loss_D_real.item())\n",
    "            loss_D_fake_list.append(loss_D_fake.item())\n",
    "\n",
    "        # Update learning rates\n",
    "        lr_scheduler_G.step()\n",
    "        lr_scheduler_D_A.step()\n",
    "        lr_scheduler_D_B.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_B_src, fake_B_lens = netG_A2B(fixed_A_src, fixed_A_lens)\n",
    "            fake_A_src, fake_A_lens = netG_B2A(fixed_B_src, fixed_B_lens)\n",
    "        B_tweets_list.append(tokens_to_sentences(fake_B_src, fake_B_lens, vocab_itos))\n",
    "        A_tweets_list.append(tokens_to_sentences(fake_A_src, fake_A_lens, vocab_itos))\n",
    "\n",
    "    ########### show translation evolution ###########\n",
    "\n",
    "    with open(\"models/\" + model_name + '_evolution.txt', 'w') as f:\n",
    "\n",
    "        f.write('=' * 100 + '\\n')\n",
    "        f.write('Source tweets examples from ' + user_A +'\\n')\n",
    "        f.write('=' * 100 + '\\n')\n",
    "\n",
    "        fixed_sentences = tokens_to_sentences(fixed_A_src, fixed_A_lens, vocab_itos)\n",
    "        for sentence in fixed_sentences:\n",
    "            f.write(\" \".join(sentence) + '\\n')\n",
    "        f.write('='*100 + '\\n')\n",
    "\n",
    "        f.write('=' * 100 + '\\n')\n",
    "        f.write('Translated tweets examples from ' + user_A + ' to ' + user_B + '\\n')\n",
    "        f.write('=' * 100 + '\\n')\n",
    "\n",
    "        for epoch, sentences in enumerate(B_tweets_list):\n",
    "            f.write('epoch:' + str(epoch) + '\\n')\n",
    "            for sentence in sentences:\n",
    "                f.write(\" \".join(sentence) + '\\n')\n",
    "            f.write('='*100 + '\\n')\n",
    "\n",
    "        f.write('\\n')\n",
    "\n",
    "        f.write('=' * 100 + '\\n')\n",
    "        f.write('Source tweets examples from ' + user_B + '\\n')\n",
    "        f.write('=' * 100 + '\\n')\n",
    "\n",
    "        fixed_sentences = tokens_to_sentences(fixed_B_src, fixed_B_lens, vocab_itos)\n",
    "        for sentence in fixed_sentences:\n",
    "            f.write(\" \".join(sentence) + '\\n')\n",
    "        f.write('=' * 100 + '\\n')\n",
    "\n",
    "        f.write('=' * 100 + '\\n')\n",
    "        f.write('Translated tweets examples from ' + user_B + ' to ' + user_A + '\\n')\n",
    "        f.write('=' * 100 + '\\n')\n",
    "\n",
    "        for epoch, sentences in enumerate(A_tweets_list):\n",
    "            f.write('epoch:' + str(epoch) + '\\n')\n",
    "            for sentence in sentences:\n",
    "                f.write(\" \".join(sentence) + '\\n')\n",
    "            f.write('=' * 100 + '\\n')\n",
    "\n",
    "    ################## plot results ##################\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Generators and Discriminators Loss During Training\")\n",
    "    plt.plot(G_losses, label=\"Generators\")\n",
    "    plt.plot(D_losses, label=\"Discriminators\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig('images/' + model_name + '_losses.eps', format='eps', dpi=1200)\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Discriminators Frequency of Predicting \\\"Real\\\" During Training\")\n",
    "    plt.plot(D_x_list, label=\"Real Data\")\n",
    "    plt.plot(D_G_x_list, label=\"False Data\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.savefig('images/' + model_name + '_discriminators_frequencies.eps', format='eps', dpi=1200)\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Identity, Cycle, and GAN Loss During Generators Training\")\n",
    "    plt.plot(loss_identity_list, label=\"Identity Loss\")\n",
    "    plt.plot(loss_cycle_list, label=\"Cycle Loss\")\n",
    "    plt.plot(loss_GAN_list, label=\"GAN Loss\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig('images/' + model_name + '_generators_loss.eps', format='eps', dpi=1200)\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Discriminator GAN Loss in Real and Fake Data during Training\")\n",
    "    plt.plot(loss_D_real_list, label=\"Real Data\")\n",
    "    plt.plot(loss_D_fake_list, label=\"Fake Data\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig('images/' + model_name + '_discriminators_loss.eps', format='eps', dpi=1200)\n",
    "\n",
    "    ################ saving the model ################\n",
    "\n",
    "    netG_A2B_params = netG_A2B.state_dict()\n",
    "\n",
    "    netG_A2B_kwargs = {'input_vocab_size': vocab_size, 'output_vocab_size': vocab_size,\n",
    "                       'embedded_size': G_embedded_size, 'n_heads': G_n_heads, 'n_hidden': G_n_hidden,\n",
    "                       'n_layers': G_n_layers, 'dropout': G_dropout}\n",
    "\n",
    "    save_model(model_name + '_netG_A2B', netG_A2B_params, netG_A2B_kwargs)\n",
    "\n",
    "    netG_B2A_params = netG_B2A.state_dict()\n",
    "\n",
    "    netG_B2A_kwargs = {'input_vocab_size': vocab_size, 'output_vocab_size': vocab_size,\n",
    "                       'embedded_size': G_embedded_size, 'n_heads': G_n_heads, 'n_hidden': G_n_hidden,\n",
    "                       'n_layers': G_n_layers, 'dropout': G_dropout}\n",
    "\n",
    "    save_model(model_name + '_netG_B2A', netG_B2A_params, netG_B2A_kwargs)\n",
    "\n",
    "    netD_A_params = netD_A.state_dict()\n",
    "\n",
    "    netD_A_kwargs = {'vocab_size':vocab_size, 'embedded_size': D_embedded_size, 'n_heads': D_n_heads,\n",
    "                     'n_hidden': D_n_hidden, 'n_layers': D_n_layers, 'dropout': D_dropout}\n",
    "\n",
    "    save_model(model_name + '_netD_A', netD_A_params, netD_A_kwargs)\n",
    "\n",
    "    netD_B_params = netD_B.state_dict()\n",
    "\n",
    "    netD_B_kwargs = {'vocab_size': vocab_size, 'embedded_size': D_embedded_size, 'n_heads': D_n_heads,\n",
    "                     'n_hidden': D_n_hidden, 'n_layers': D_n_layers, 'dropout': D_dropout}\n",
    "\n",
    "    save_model(model_name + '_netD_B', netD_B_params, netD_B_kwargs)\n",
    "\n",
    "    return netG_A2B, netG_B2A, netD_A, netD_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_name, model_params, model_kwargs):\n",
    "\n",
    "    params_path = 'models/' + model_name + '_params.pt'\n",
    "\n",
    "    torch.save(model_params, params_path)\n",
    "\n",
    "    kwargs_path = 'models/' + model_name + '_kwargs.json'\n",
    "\n",
    "    with open(kwargs_path, 'w') as kwargs_file:\n",
    "        json.dump(model_kwargs, kwargs_file, sort_keys=True, indent=4)\n",
    "\n",
    "    print(model_name, 'saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, device):\n",
    "\n",
    "    netG_A2B_kwargs_path = 'models/' + model_name + '_netG_A2B_kwargs.json'\n",
    "    with open(netG_A2B_kwargs_path, 'r') as netG_A2B_kwargs_file:\n",
    "        netG_A2B_kwargs = json.load(netG_A2B_kwargs_file)\n",
    "\n",
    "    netG_A2B = Generator(**netG_A2B_kwargs).to(device)\n",
    "\n",
    "    netG_A2B_params_path = 'models/' + model_name + '_netG_A2B_params.pt'\n",
    "\n",
    "    netG_A2B.load_state_dict(torch.load(netG_A2B_params_path))\n",
    "    netG_A2B.eval()\n",
    "\n",
    "    netG_B2A_kwargs_path = 'models/' + model_name + '_netG_B2A_kwargs.json'\n",
    "    with open(netG_B2A_kwargs_path, 'r') as netG_B2A_kwargs_file:\n",
    "        netG_B2A_kwargs = json.load(netG_B2A_kwargs_file)\n",
    "\n",
    "    netG_B2A = Generator(**netG_B2A_kwargs).to(device)\n",
    "\n",
    "    netG_B2A_params_path = 'models/' + model_name + '_netG_B2A_params.pt'\n",
    "\n",
    "    netG_B2A.load_state_dict(torch.load(netG_B2A_params_path))\n",
    "    netG_B2A.eval()\n",
    "\n",
    "    netD_A_kwargs_path = 'models/' + model_name + '_netD_A_kwargs.json'\n",
    "    with open(netD_A_kwargs_path, 'r') as netD_A_kwargs_file:\n",
    "        netD_A_kwargs = json.load(netD_A_kwargs_file)\n",
    "\n",
    "    netD_A = Discriminator(**netD_A_kwargs).to(device)\n",
    "\n",
    "    netD_A_params_path = 'models/' + model_name + '_netD_A_params.pt'\n",
    "\n",
    "    netD_A.load_state_dict(torch.load(netD_A_params_path))\n",
    "    netD_A.eval()\n",
    "\n",
    "    netD_B_kwargs_path = 'models/' + model_name + '_netD_B_kwargs.json'\n",
    "    with open(netD_B_kwargs_path, 'r') as netD_B_kwargs_file:\n",
    "        netD_B_kwargs = json.load(netD_B_kwargs_file)\n",
    "\n",
    "    netD_B = Discriminator(**netD_B_kwargs).to(device)\n",
    "\n",
    "    netD_B_params_path = 'models/' + model_name + '_netD_B_params.pt'\n",
    "\n",
    "    netD_B.load_state_dict(torch.load(netD_B_params_path))\n",
    "    netD_B.eval()\n",
    "\n",
    "    print(model_name, 'loaded with device', str(generator.device))\n",
    "\n",
    "    return netG_A2B, netG_B2A, netD_A, netD_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_name, device):\n",
    "\n",
    "    netG_A2B, netG_B2A, netD_A, netD_B = load_model(model_name, device)\n",
    "\n",
    "    print(netG_A2B.state_dict())\n",
    "    print(netG_B2A.state_dict())\n",
    "    print(netD_A.state_dict())\n",
    "    print(netD_B.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(s):\n",
    "    words = s.split(' ')\n",
    "    websites = []\n",
    "    for word in words:\n",
    "        if 'http' in word:\n",
    "            websites.append(word)\n",
    "    for website in websites:\n",
    "        words.remove(website)\n",
    "    s = \" \".join(words)\n",
    "    words = re.split(r'(\\W)', s)\n",
    "    n_spaces, n_blanks, n_breaks, n_r = 0, 0, 0, 0\n",
    "    for word in words:\n",
    "        if word == ' ':\n",
    "            n_spaces += 1\n",
    "        if word == '':\n",
    "            n_blanks += 1\n",
    "        if word == '\\n':\n",
    "            n_breaks += 1\n",
    "        if word == '\\r':\n",
    "            n_r += 1\n",
    "    for space in range(n_spaces):\n",
    "        words.remove(\" \")\n",
    "    for blank in range(n_blanks):\n",
    "        words.remove('')\n",
    "    for line_break in range(n_breaks):\n",
    "        words.remove('\\n')\n",
    "    for r in range(n_r):\n",
    "        words.remove('\\r')\n",
    "    s = \" \".join(words)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_user_data(user, n_tweets):\n",
    "\n",
    "    dataset = pd.read_csv('data/dataset.csv', lineterminator='\\n')\n",
    "\n",
    "    data = dataset[dataset['user'] == user]['text']\n",
    "\n",
    "    data = pd.Series(map(prepare_text, data))\n",
    "    data = pd.DataFrame(data, columns=['text'])\n",
    "\n",
    "    data['text'].replace('', np.nan, inplace=True)\n",
    "    data.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "    data = data[:n_tweets]\n",
    "\n",
    "    data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    pct_train, pct_val = (0.8, 0.1)\n",
    "    n_train = math.floor(n_tweets * pct_train)\n",
    "    n_val = math.floor(n_tweets * pct_val)\n",
    "\n",
    "    data_train = data[:n_train].reset_index()\n",
    "    data_val = data[n_train:n_train + n_val].reset_index()\n",
    "    data_test = data[n_train + n_val:].reset_index()\n",
    "\n",
    "    os.mkdir('data/' + user)\n",
    "\n",
    "    data_train.to_csv('data/' + user + '/train.csv', index_label='index')\n",
    "    data_val.to_csv('data/' + user + '/val.csv', index_label='index')\n",
    "    data_test.to_csv('data/' + user + '/test.csv', index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(mode='train', manualSeed=999, model_name=\"\", user_A=\"\", user_B=\"\", n_epochs=\"\", decay_epoch=\"\"):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print('device is:', device)\n",
    "\n",
    "    print(\"Random Seed: \", manualSeed)\n",
    "    torch.manual_seed(manualSeed)\n",
    "    random.seed(manualSeed)\n",
    "\n",
    "\n",
    "    if mode == 'train':\n",
    "        netG_A2B, netG_B2A, netD_A, netD_B = train_model(model_name=model_name, user_A=user_A, user_B=user_B,\n",
    "                                                         n_epochs=n_epochs, decay_epoch=decay_epoch, device=device)\n",
    "\n",
    "    if mode == 'test':\n",
    "        model_name = sys.argv[2]\n",
    "        test_model(model_name=model_name, device=device)\n",
    "\n",
    "    if mode == 'prepare_user_data':\n",
    "        user = sys.argv[2]\n",
    "        n_tweets = int(sys.argv[3])\n",
    "        prepare_user_data(user, n_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is: cuda\n",
      "Random Seed:  999\n",
      "vocab size: 8531\n",
      "Starting Training Loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/32][0/98]\tLoss_D: 0.8299\tLoss_G: 2.8977\tD(x): 0.4625\tD(G(x)): 0.4658\n"
     ]
    }
   ],
   "source": [
    "run(model_name='joao_teste', user_A=\"@realDonaldTrump\", user_B=\"@BernieSanders\", n_epochs=32, decay_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
